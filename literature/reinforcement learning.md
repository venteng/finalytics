# literature review for reinforcement learning

## Template 



|keywords | 	Journal Ranking Factor |	#Citation |	bibentry|
|--|---|---|---|
|LASSO| 	SCIE: 3/125 = 2%	|55855|	"@article{tibshirani1996regression, title={Regression shrinkage and selection via the lasso}, author={Tibshirani, Robert}, journal={Journal of the Royal Statistical Society Series B: Statistical Methodology}, volume={58},number={1}, pages={267--288},  year={1996},publisher={Oxford University Press}}"|




## Reinforcement learning by Mark Wu

|keywords | 	Journal Ranking Factor |	#Citation |	bibentry|
|--|---|---|---|
|high-frequency trade| 	NA	|24|	"@article{dixon2018high,  title={A high-frequency trade execution model for supervised learning}, author={Dixon, Matthew}, journal={High Frequency}, volume={1}, number={1}, pages={32--52}, year={2018}, publisher={Wiley Online Library}}"|
|Algorithmic trading of cryptocurrency| 	NA	|127|	"@article{colianni2015algorithmic, title={Algorithmic trading of cryptocurrency based on Twitter sentiment analysis}, author={Colianni, Stuart and Rosales, Stephanie and Signorotti, Michael}, journal={CS229 Project}, volume={1}, number={5}, pages={1--4}, year={2015}}"|
|Advances in financial machine learning| 	NA	|658|	"@book{de2018advances, title={Advances in financial machine learning}, author={De Prado, Marcos Lopez}, year={2018}, publisher={John Wiley \& Sons}}"|
|Universal features of price formation| 	NA	|316|	"@incollection{sirignano2021universal, title={Universal features of price formation in financial markets: perspectives from deep learning}, author={Sirignano, Justin and Cont, Rama}, booktitle={Machine Learning and AI in Finance}, pages={5--15}, year={2021}, publisher={Routledge}}"|
|Empirical asset pricing| 	SSCI: 4/111 = 3.6%	|1780|	"@article{gu2020empirical,title={Empirical asset pricing via machine learning}, author={Gu, Shihao and Kelly, Bryan and Xiu, Dacheng}, journal={The Review of Financial Studies}, volume={33}, number={5}, pages={2223--2273}, year={2020}, publisher={Oxford University Press}}"|
|Reinforcement learning| 	SCIE: 151/272	= 55.5%|274|	"@article{sutton1999reinforcement, title={Reinforcement learning}, author={Sutton, Richard S and Barto, Andrew G and others}, journal={Journal of Cognitive Neuroscience}, volume={11},number={1}, pages={126--134}, year={1999}}"|
|Playing atari with deep reinforcement learning| 	NA	|14402|	"@article{mnih2013playing,title={Playing atari with deep reinforcement learning}, author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin}, journal={arXiv preprint arXiv:1312.5602}, year={2013}}"|
|Deep reinforcement learning for trading| 	NA	|210|	"@article{zhang2019deep,title={Deep reinforcement learning for trading},author={Zhang, Zihao and Zohren, Stefan and Roberts, Stephen},journal={arXiv preprint arXiv:1911.10107}, year={2019}}"|
|Deep reinforcement learning for automated stock trading| 	NA	|211|	"@inproceedings{yang2020deep,title={Deep reinforcement learning for automated stock trading: An ensemble strategy}, author={Yang, Hongyang and Liu, Xiao-Yang and Zhong, Shan and Walid, Anwar}, booktitle={Proceedings of the first ACM international conference on AI in finance}, pages={1--8}, year={2020}}"|
|Policy gradient| 	NA	|8091|	"@article{sutton1999policy,title={Policy gradient methods for reinforcement learning with function approximation},author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},journal={Advances in neural information processing systems},volume={12},year={1999}}"|
|Deterministic policy gradient| 	SCIE: 14/65	= 21.5%|4851|	"@inproceedings{silver2014deterministic,title={Deterministic policy gradient algorithms},author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin}, booktitle={International conference on machine learning},pages={387--395}, year={2014}, organization={Pmlr}}"|
|Proximal policy optimization| 	NA	|17074|	"@article{schulman2017proximal, title={Proximal policy optimization algorithms}, author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg}, journal={arXiv preprint arXiv:1707.06347},year={2017}}"|
|Asynchronous methods for deep reinforcement learning| 	SCIE: 14/65	= 21.5%|10789|	"@inproceedings{mnih2016asynchronous,title={Asynchronous methods for deep reinforcement learning}, author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray}, booktitle={International conference on machine learning}, pages={1928--1937},year={2016},organization={PMLR}}"|
## Please use VPN with NYCU connection to find the SCI/SCIE's ranking factor through https://jcr.clarivate.com/jcr/home. If you can not find the paper, please write NA. 
